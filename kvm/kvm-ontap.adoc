---
sidebar: sidebar 
permalink: kvm/kvm-ontap.html 
keywords: netapp, kvm, libvirt, all-flash, nfs, iscsi, ontap, storage, aff 
summary: KVM 主機中的共享儲存減少了 VM 即時遷移的時間，並為整個環境中的備份和一致模板提供了更好的目標。  ONTAP儲存可以滿足 KVM 主機環境以及客戶文件、區塊和物件儲存需求。 
---
= 了解如何將ONTAP儲存與 KVM 虛擬化環境集成
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
透過使用 Libvirt 將ONTAP儲存與 KVM 虛擬化環境集成，提高效能、資料保護和營運效率。了解 ONTAP 的企業級儲存功能如何透過靈活的 NFS、iSCSI 和光纖通道協定支援 KVM 主機基礎架構和客戶虛擬機器儲存需求。

KVM 主機中的共享儲存減少了 VM 即時遷移的時間，並為整個環境中的備份和一致模板提供了更好的目標。  ONTAP儲存可以滿足 KVM 主機環境以及客戶文件、區塊和物件儲存需求。

KVM 主機需要將 FC、乙太網路或其他支援的介面連接到交換機，並與ONTAP邏輯介面進行通訊。始終檢查 https://mysupport.netapp.com/matrix/#welcome["互通性矩陣工具"]了解支援的配置。



== 進階ONTAP功能

*共同特徵*

* 擴展集群
* 安全性身份驗證和 RBAC 支持
* 零信任多管理員支持
* 安全多租戶
* 使用SnapMirror複製資料。
* 使用快照進行時間點複製。
* 節省空間的克隆。
* 儲存效率功能，如重複資料刪除、壓縮等。
* Trident CSI 對 Kubernetes 的支持
* Snaplock
* 防篡改快照副本鎖定
* 加密支援
* FabricPool將冷資料分層到物件儲存。
* BlueXP和Data Infrastructure Insights整合。
* Microsoft 卸載資料傳輸 (ODX)


*NAS*

* FlexGroup磁碟區是一個橫向擴充 NAS 容器，提供高效能以及負載分配和可擴充性。
* FlexCache允許資料在全球分發，同時仍提供對資料的本地讀寫存取。
* 多重協定支援使得相同的資料可以透過 SMB 和 NFS 存取。
* NFS nConnect 允許每個 TCP 連線建立多個 TCP 會話，從而增加網路吞吐量。這增加了現代伺服器上可用的高速網路卡的使用率。
* NFS 會話中繼提供了更高的資料傳輸速度、高可用性和容錯能力。
* pNFS 用於優化資料路徑連接。
* SMB 多通道提供了更高的資料傳輸速度、高可用性和容錯能力。
* 與 Active Directory/LDAP 整合以取得檔案權限。
* 透過 TLS 與 NFS 建立安全連線。
* NFS Kerberos 支援。
* 透過 RDMA 實現的 NFS。
* Windows 與 Unix 身分之間的名稱對應。
* 自主勒索軟體保護。
* 文件系統分析。


*SAN*

* 使用SnapMirror主動同步跨故障域擴展叢集。
* ASA模型提供主動/主動多路徑和快速路徑故障轉移。
* 支援FC、iSCSI、NVMe-oF協定。
* 支援 iSCSI CHAP 相互認證。
* 選擇性 LUN 對映和連接埠集。




== 帶有ONTAP存儲的 Libvirt

Libvirt 可用於管理利用NetApp ONTAP儲存其磁碟映像和資料的虛擬機器。透過這種集成，您可以在基於 Libvirt 的虛擬化環境中受益於 ONTAP 的高級儲存功能，例如資料保護、儲存效率和效能最佳化。以下是 Libvirt 與ONTAP互動的方式以及您可以執行的操作：

. 儲存池管理：
+
** 將ONTAP儲存定義為 Libvirt 儲存池：您可以設定 Libvirt 儲存池以透過 NFS、iSCSI 或光纖通道等協定指向ONTAP磁碟區或 LUN。
** Libvirt 管理池內的磁碟區：一旦定義了儲存池，Libvirt 就可以管理該池內與ONTAP LUN 或檔案相對應的磁碟區的建立、刪除、複製和快照。
+
*** 範例：NFS 儲存池：如果您的 Libvirt 主機從ONTAP掛載 NFS 共用，則可以在 Libvirt 中定義基於 NFS 的儲存池，它會將共用中的檔案列為可用於 VM 磁碟的磁碟區。




. 虛擬機器磁碟儲存：
+
** 在ONTAP上儲存虛擬機器磁碟映像：您可以在由ONTAP儲存支援的 Libvirt 儲存池中建立虛擬機器磁碟映像（例如，qcow2、raw）。
** 受益於 ONTAP 的儲存功能：當 VM 磁碟儲存在ONTAP磁碟區上時，它們會自動受益於 ONTAP 的資料保護（快照、 SnapMirror、 SnapVault）、儲存效率（重複資料刪除、壓縮）和效能功能。


. 資料保護：
+
** 自動資料保護： ONTAP提供自動資料保護功能，包括快照和SnapMirror等功能，可透過將您寶貴的資料複製到其他ONTAP儲存（無論是在本地、遠端站點還是在雲端）來保護您的寶貴資料。
** RPO 和 RTO：您可以使用 ONTAP 的資料保護功能來實現低復原點目標 (RPO) 和快速復原時間目標 (RTO)。
** MetroCluster/ SnapMirror主動同步：為了實現自動零 RPO（恢復點目標）和站點到站點可用性，您可以使用ONTAP MetroCluster或 SMas，這使得能夠在站點之間建立延伸叢集。


. 性能和效率：
+
** Virtio 驅動程式：在您的客戶虛擬機器中使用 Virtio 網路和磁碟裝置驅動程式來提高效能。這些驅動程式旨在與虛擬機器管理程式協作並提供半虛擬化優勢。
** Virtio-SCSI：為了實現可擴充性和進階儲存功能，請使用 Virtio-SCSI，它能夠直接連接到 SCSI LUN 並處理大量設備。
** 儲存效率：ONTAP 的儲存效率功能（例如重複資料刪除、壓縮和壓縮）可以幫助減少虛擬機器磁碟的儲存空間，從而節省成本。


. ONTAP Select整合：
+
** KVM 上的ONTAP Select ： ONTAP Select是 NetApp 的軟體定義儲存解決方案，可部署在 KVM 主機上，為基於 Libvirt 的虛擬機器提供靈活且可擴充的儲存平台。
** ONTAP Select Deploy： ONTAP Select Deploy 是一種用於建立和管理ONTAP Select叢集的工具。它可以作為虛擬機器在 KVM 或 VMware ESXi 上運行。




本質上，將 Libvirt 與ONTAP結合使用，您可以將基於 Libvirt 的虛擬化的靈活性和可擴展性與ONTAP的企業級資料管理功能相結合，為您的虛擬化環境提供強大而高效的解決方案。



== 基於檔案的儲存池（使用 SMB 或 NFS）

dir 和 netfs 類型的儲存池適用於基於檔案的儲存。

[cols="30%, 10%, 10% ,10%, 10%, 10,% 10%, 10%"]
|===
| 儲存協定 | 目錄 | 檔案系統 | 淨流表 | 邏輯 | 磁碟 | 網路連線 


| iscsi直接 | mpath | 中小企業/CIFS | 是的 | 不 | 是的 | 不 


| 不 | 不 | 不 | 不 | NFS | 是的 | 不 
|===
使用 netfs，libvirt 將掛載檔案系統，並且支援的掛載選項有限。使用 dir 儲存池，檔案系統的掛載需要在主機外部處理。可以使用 fstab 或自動掛載程式來實現此目的。要使用自動掛載程序，需要安裝 autofs 套件。 Autofs 對於按需掛載網路共用特別有用，與 fstab 中的靜態掛載相比，這可以提高系統效能和資源利用率。一段時間不活動後，它會自動卸載共享。

根據所使用的儲存協議，驗證主機上是否安裝了所需的套件。

[cols="40%, 20,% 20%, 20%"]
|===
| 儲存協定 | Fedora | Debian 


| 吃豆人 | 中小企業/CIFS | samba 客戶端/cifs-utils 


| smbclient/cifs實用程式 | smbclient/cifs實用程式 | NFS 


| nfs實用程式 | nfs-通用 | nfs實用程式 
|===
NFS 因其在 Linux 中的原生支援和效能而成為一種流行的選擇，而 SMB 則是與 Microsoft 環境整合的可行選擇。在生產中使用之前，請務必檢查支援矩陣。

根據選擇的協議，請按照適當的步驟建立 SMB 共享或 NFS 導出。https://docs.netapp.com/us-en/ontap-system-manager-classic/smb-config/index.html["SMB 共享建立"] https://docs.netapp.com/us-en/ontap-system-manager-classic/nfs-config/index.html["NFS 導出創建"]

在 fstab 或自動掛載器設定檔中包含掛載選項。例如，使用 autofs 時，我們在 /etc/auto.master 中包含以下行，以使用檔案 auto.kvmfs01 和 auto.kvmsmb01 進行直接映射

/- /etc/auto.kvmnfs01 --timeout=60 /- /etc/auto.kvmsmb01 --timeout=60 --ghost

在 /etc/auto.kvmnfs01 檔案中，我們有 /mnt/kvmnfs01 -trunkdiscovery,nconnect=4 172.21.35.11,172.21.36.11(100):/kvmnfs01

對於 smb，在 /etc/auto.kvmsmb01 中，我們有 /mnt/kvmsmb01 -fstype=cifs,credentials=/root/smbpass,multichannel,max_channels=8 ://kvmfs01.sddc.netapp.com/kvmsmb01

使用池類型為 dir 的 virsh 定義儲存池。

[source, shell]
----
virsh pool-define-as --name kvmnfs01 --type dir --target /mnt/kvmnfs01
virsh pool-autostart kvmnfs01
virsh pool-start kvmnfs01
----
可以使用

[source, shell]
----
virsh vol-list kvmnfs01
----
為了優化基於 NFS 掛載的 Libvirt 儲存池的效能，會話中繼、pNFS 和 nconnect 掛載選項這三個選項都可以發揮作用，但它們的有效性取決於您的特定需求和環境。以下分類可以幫助您選擇最佳方法：

. n連接：
+
** 最適合：透過使用多個 TCP 連線對 NFS 掛載本身進行簡單、直接的最佳化。
** 工作原理：nconnect 掛載選項可讓您指定 NFS 用戶端將與 NFS 端點（伺服器）建立的 TCP 連線數。這可以顯著提高受益於多個並發連接的工作負載的吞吐量。
** 好處：
+
*** 易於配置：只需將 nconnect=<number_of_connections> 新增至您的 NFS 掛載選項即可。
*** 提高吞吐量：增加 NFS 流量的「管道寬度」。
*** 對各種工作負載有效：適用於通用虛擬機器工作負載。


** 限制：
+
*** 客戶端/伺服器支援：需要客戶端（Linux 核心）和 NFS 伺服器（例如ONTAP）都支援 nconnect。
*** 飽和度：設定非常高的 nconnect 值可能會使您的網路線路飽和。
*** 每次掛載設定：nconnect 值是為初始掛載設定的，並且所有後續掛載到同一伺服器和版本都會繼承此值。




. 會話中繼：
+
** 最適合：透過利用多個網路介面 (LIF) 到 NFS 伺服器來增強吞吐量並提供一定程度的彈性。
** 工作原理：會話中繼允許 NFS 用戶端開啟與 NFS 伺服器上不同 LIF 的多個連接，從而有效地聚合多個網路路徑的頻寬。
** 好處：
+
*** 提高資料傳輸速度：透過利用多條網路路徑。
*** 彈性：如果網路路徑發生故障，其他路徑仍然可以使用，儘管故障路徑上正在進行的操作可能會掛起，直到重新建立連線。


** 限制：仍然是單一 NFS 會話：雖然它使用多個網路路徑，但它不會改變傳統 NFS 的基本單會話性質。
** 配置複雜性：需要在ONTAP伺服器上設定中繼組和 LIF。網路設定：需要合適的網路基礎架構來支援多路徑。
** 使用 nConnect 選項：只有第一個介面才會套用 nConnect 選項。其餘介面將具有單一連接。


. pNFS：
+
** 最適合：高效能、橫向擴展工作負載，可從平行資料存取和儲存設備的直接 I/O 中受益。
** 如何運作：pNFS 分離元資料和資料路徑，允許客戶端直接從儲存存取數據，從而可能繞過 NFS 伺服器進行資料存取。
** 好處：
+
*** 提高可擴展性和效能：對於受益於並行 I/O 的特定工作負載（如 HPC 和 AI/ML）。
*** 直接數據存取：允許客戶端直接從儲存讀取/寫入數據，從而減少延遲並提高效能。
*** 使用 nConnect 選項：所有連線都會套用 nConnect 以最大化網路頻寬。


** 限制：
+
*** 複雜性：pNFS 的設定和管理比傳統 NFS 或 nconnect 更複雜。
*** 特定於工作負載：並非所有工作負載都能從 pNFS 中受益匪淺。
*** 客戶端支援：需要客戶端支援pNFS。






建議：* 對於 NFS 上的通用 Libvirt 儲存池：從 nconnect 掛載選項開始。它相對容易實現，並且可以透過增加連接數量來提供良好的性能提升。 * 如果您需要更高的吞吐量和彈性：請考慮在 nconnect 之外或之外使用會話中繼。在 Libvirt 主機和ONTAP系統之間具有多個網路介面的環境中，這會非常有用。 * 對於受益於並行 I/O 的苛刻工作負載：如果您正在運行可以利用平行資料存取的 HPC 或 AI/ML 等工作負載，那麼 pNFS 可能是您的最佳選擇。然而，請做好應對設定和配置日益複雜的準備。始終使用不同的掛載選項和設定測試和監控您的 NFS 效能，以確定特定 Libvirt 儲存池和工作負載的最佳配置。



== 基於區塊的儲存池（帶有 iSCSI、FC 或 NVMe-oF）

目錄池類型通常在共用 LUN 或命名空間上的叢集檔案系統（如 OCFS2 或 GFS2）上使用。

根據所使用的儲存協定驗證主機是否安裝了必要的軟體包。

[cols="40%, 20%, 20%, 20%"]
|===
| 儲存協定 | Fedora | Debian | 吃豆人 


| iSCSI | iscsi 啟動器實用程式、裝置映射器多路徑、ocfs2 工具/gfs2 實用程式 | open-iscsi、多路徑工具、ocfs2 工具/gfs2 實用程式 | open-iscsi、多路徑工具、ocfs2 工具/gfs2 實用程式 


| FC | 裝置映射器多路徑，ocfs2 工具/gfs2 實用程式 | 多路徑工具、ocfs2 工具/gfs2 實用程式 | 多路徑工具、ocfs2 工具/gfs2 實用程式 


| NVMe-oF | nvme-cli、ocfs2-工具/gfs2-utils | nvme-cli、ocfs2-工具/gfs2-utils | nvme-cli、ocfs2-工具/gfs2-utils 
|===
收集主機iqn/wwpn/nqn。

[source, shell]
----
# To view host iqn
cat /etc/iscsi/initiatorname.iscsi
# To view wwpn
systool -c fc_host -v
# or if you have ONTAP Linux Host Utility installed
sanlun fcp show adapter -v
# To view nqn
sudo nvme show-hostnqn
----
請參閱對應部分來建立 LUN 或命名空間。

https://docs.netapp.com/us-en/ontap-system-manager-classic/iscsi-config-rhel/index.html["為 iSCSI 主機建立 LUN"] https://docs.netapp.com/us-en/ontap-system-manager-classic/fc-config-rhel/index.html["為 FC 主機建立 LUN"] https://docs.netapp.com/us-en/ontap/san-admin/create-nvme-namespace-subsystem-task.html["為 NVMe-oF 主機建立命名空間"]

確保 FC 分區或乙太網路設備配置為與ONTAP邏輯介面通訊。

對於 iSCSI，

[source, shell]
----
# Register the target portal
iscsiadm -m discovery -t st -p 172.21.37.14
# Login to all interfaces
iscsiadm -m node -L all
# Ensure iSCSI service is enabled
sudo systemctl enable iscsi.service
# Verify the multipath device info
multipath -ll
# OCFS2 configuration we used.
o2cb add-cluster kvmcl01
o2cb add-node kvm02.sddc.netapp.com
o2cb cluster-status
mkfs.ocfs2 -L vmdata -N 4  --cluster-name=kvmcl01 --cluster-stack=o2cb -F /dev/mapper/3600a098038314c57312b58387638574f
mount -t ocfs2 /dev/mapper/3600a098038314c57312b58387638574f1 /mnt/kvmiscsi01/
mounted.ocfs2 -d
# For libvirt storage pool
virsh pool-define-as --name kvmiscsi01 --type dir --target /mnt/kvmiscsi01
virsh pool-autostart kvmiscsi01
virsh pool-start kvmiscsi01
----
對於 NVMe/TCP，我們使用

[source, shell]
----
# Listing the NVMe discovery
cat /etc/nvme/discovery.conf
# Used for extracting default parameters for discovery
#
# Example:
# --transport=<trtype> --traddr=<traddr> --trsvcid=<trsvcid> --host-traddr=<host-traddr> --host-iface=<host-iface>
-t tcp -l 1800 -a 172.21.37.16
-t tcp -l 1800 -a 172.21.37.17
-t tcp -l 1800 -a 172.21.38.19
-t tcp -l 1800 -a 172.21.38.20
# Login to all interfaces
nvme connect-all
nvme list
# Verify the multipath device info
nvme show-topology
# OCFS2 configuration we used.
o2cb add-cluster kvmcl01
o2cb add-node kvm02.sddc.netapp.com
o2cb cluster-status
mkfs.ocfs2 -L vmdata1 -N 4  --cluster-name=kvmcl01 --cluster-stack=o2cb -F /dev/nvme2n1
mount -t ocfs2 /dev/nvme2n1 /mnt/kvmns01/
mounted.ocfs2 -d
# To change label
tunefs.ocfs2 -L tme /dev/nvme2n1
# For libvirt storage pool
virsh pool-define-as --name kvmns01 --type dir --target /mnt/kvmns01
virsh pool-autostart kvmns01
virsh pool-start kvmns01
----
對於 FC，

[source, shell]
----
# Verify the multipath device info
multipath -ll
# OCFS2 configuration we used.
o2cb add-cluster kvmcl01
o2cb add-node kvm02.sddc.netapp.com
o2cb cluster-status
mkfs.ocfs2 -L vmdata2 -N 4  --cluster-name=kvmcl01 --cluster-stack=o2cb -F /dev/mapper/3600a098038314c57312b583876385751
mount -t ocfs2 /dev/mapper/3600a098038314c57312b583876385751 /mnt/kvmfc01/
mounted.ocfs2 -d
# For libvirt storage pool
virsh pool-define-as --name kvmfc01 --type dir --target /mnt/kvmfc01
virsh pool-autostart kvmfc01
virsh pool-start kvmfc01
----
注意：裝置掛載應包含在 /etc/fstab 中或使用自動掛載對映檔案。

Libvirt 管理叢集檔案系統上的虛擬磁碟（檔案）。它依賴叢集檔案系統（OCFS2 或 GFS2）來處理底層共用區塊存取和資料完整性。  OCFS2 或 GFS2 充當 Libvirt 主機和共用區塊儲存之間的抽象層，提供必要的鎖定和協調，以允許安全地並發存取儲存在該共用儲存上的虛擬磁碟映像。
